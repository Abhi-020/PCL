{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":" BertXlm.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1AS-3uKPlmnpB6iItrzn5uQnHtCbtHkK9","authorship_tag":"ABX9TyOBNfNht8tkb996Ptb85ohy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"oQ9SD-cUNV7s"},"outputs":[],"source":["import pandas as pd\n","df = pd.read_csv( './drive/MyDrive/Data/dontpatronizeme_pcl.tsv', sep = '\\t', names=['id','info','country', 'text','label'] )\n","df"]},{"cell_type":"code","source":["!pip install sentencepiece transformers\n"],"metadata":{"id":"klT3827qSfFA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test_= pd.read_csv( './drive/MyDrive/Data/pcl_test.tsv', sep = '\\t', names=['seq','id','info','country', 'text','label_'] )\n","df_test_"],"metadata":{"id":"pfK93Kr0r0o7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test= df_test_[['text','label_']]\n","df_test"],"metadata":{"id":"Fjxr21hCs1Cy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test['label_'] = 1\n","df_test"],"metadata":{"id":"9k5_VR-F3fbZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","from transformers import RobertaTokenizer, RobertaModel\n","import pandas as pd\n","df = pd.read_csv('./drive/MyDrive/Data/dontpatronizeme_pcl.tsv', sep = '\\t', names=['id','info','country', 'text','label'] )\n","\n","df = df.dropna(inplace = False)\n","\n","df = df.reset_index(drop = True)\n","df.info()\n","\n","# Importing the libraries needed\n","import torch\n","import transformers\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModelForMaskedLM\n","df_final = df[['text','label']]\n","#df_data = data.dropna(subset=['id','info','country'])\n","df_final                  \n","\n","df_final.shape\n","#df_final.columns\n","df_final['label_']= [ 0 if (y == 1 or y == 0) else 1 for y in df_final['label']]\n","df_final\n","df_final.drop('label', axis = 1, inplace= True)\n","print(df_final)\n","\n","nclasses = len(list(df_final.label_.unique()))\n","nclasses\n","\n","my_classes = {c:i for i, c in enumerate(list(df_final.label_.unique()))}\n","df_final['label_'] = [my_classes[l] for l in df_final.label_]\n","\n","MAX_LEN= 512\n","TRAIN_BS = 8\n","VALID_BS = 8\n","EPOCHS = 1\n","LR =  1e-05\n","#tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","\n","class PclData(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.len = len(dataframe)\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        print(self.len); print(self.data)\n","        \n","    def __getitem__(self, index):# function compulsory\n","        sent = self.data.text[index]\n","       # sent = \" \".join(sent.split())\n","        inputs = self.tokenizer.encode_plus(\n","        sent, \n","        None,\n","        add_special_tokens = True,\n","        max_length=self.max_len,\n","        padding = 'max_length',\n","        return_token_type_ids = True,\n","        truncation=True\n","        )\n","        \n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        \n","        return { 'ids': torch.tensor(ids, dtype=torch.long),\n","               'mask': torch.tensor(mask, dtype=torch.long),\n","                'targets': torch.tensor(self.data.label_[index], dtype=torch.long)\n","                \n","               }\n","    \n","    def __len__(self):\n","        return self.len\n","        "],"metadata":{"id":"d3VtkE7WTMP2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_size = 0.8\n","train_dataset = df_final.sample(frac= train_size, random_state=20)\n","val_dataset = df_final.drop(train_dataset.index).reset_index(drop=True)\n","train_dataset = train_dataset.reset_index(drop=True)\n","test_dataset = df_test\n","\n","#train_dataset_1 = [ 0 if (y == 1 or y == 0) else 1 for y in train_dataset ]\n","#test_dataset_1 = [ 0 if (y == 1 or y == 0) else 1 for y in test_dataset ]\n","\n","\n","print(\"FULL Dataset: {}\".format(df_final.shape))\n","print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","print(\"TEST Dataset: {}\".format(val_dataset.shape))\n","\n","training_set = PclData(train_dataset, tokenizer, MAX_LEN)\n","val_set = PclData(val_dataset, tokenizer, MAX_LEN)\n","test_set= PclData(test_dataset, tokenizer, MAX_LEN)\n","\n","train_params = {'batch_size': TRAIN_BS,\n","               'shuffle':True,\n","               'num_workers': 2}\n","val_params = {'batch_size': VALID_BS,\n","              'shuffle': False,\n","              'num_workers': 2}\n","\n","trainloader = DataLoader(training_set, **train_params)\n","valloader = DataLoader(val_set, **val_params)\n","testloader = DataLoader(test_set, **val_params)"],"metadata":{"id":"zOf9q9aFTY2B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class XlmModelClass (torch.nn.Module):\n","    def __init__(self, nclasses):\n","        super(XlmModelClass, self).__init__()\n","        self.l1 = AutoModelForMaskedLM.from_pretrained('xlm-roberta-base')\n","        self.pre_classifier = torch.nn.Linear(250002, 768)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.classifier = torch.nn.Linear(768, nclasses)\n","\n","    def forward(self, input_ids, attention_mask):\n","        with torch.autograd.no_grad():\n","            output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n","            \n","        hidden_state = output_1[0]\n","        print(hidden_state.shape)\n","        pooler = hidden_state[:, 0]\n","        pooler = self.pre_classifier(pooler)\n","        pooler = torch.nn.ReLU()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output"],"metadata":{"id":"Ry83xgwMn_jW","executionInfo":{"status":"ok","timestamp":1643229111082,"user_tz":-330,"elapsed":5,"user":{"displayName":"Abhishek kumar Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03453965687970289686"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["model = XlmModelClass(nclasses)\n","model.to(device)"],"metadata":{"id":"nxXvGk81pBey"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","wt_array =len(df_final['text'])/(len(set(df_final['label_']))*(np.bincount(df_final['label_'])))\n","wt_array"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ONUmTWF_7Yp7","executionInfo":{"status":"ok","timestamp":1643229166783,"user_tz":-330,"elapsed":410,"user":{"displayName":"Abhishek kumar Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03453965687970289686"}},"outputId":"241f4d8f-7d1a-4995-bfc4-4d000ed73bae"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.55240106, 5.27089627])"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["class_weights=torch.FloatTensor(wt_array).cuda()"],"metadata":{"id":"nw83X3vw7pIC","executionInfo":{"status":"ok","timestamp":1643229171375,"user_tz":-330,"elapsed":25,"user":{"displayName":"Abhishek kumar Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03453965687970289686"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["loss_function = torch.nn.CrossEntropyLoss(weight=class_weights)\n","optimizer = torch.optim.Adam(params =model.parameters(), lr=LR)\n","def calculate_acc(big_idx, targets):\n","    n_correct = (big_idx==targets).sum().item()\n","    return n_correct\n"],"metadata":{"id":"umH-JoN3pVD7","executionInfo":{"status":"ok","timestamp":1643229173485,"user_tz":-330,"elapsed":8,"user":{"displayName":"Abhishek kumar Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03453965687970289686"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","from torch.utils.tensorboard import SummaryWriter\n","writer = SummaryWriter('runs/textclassify_experiment_1')\n","\n"],"metadata":{"id":"ZX14KNQmrDhQ","executionInfo":{"status":"ok","timestamp":1643229175259,"user_tz":-330,"elapsed":4,"user":{"displayName":"Abhishek kumar Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03453965687970289686"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["def train(epoch):\n","    tr_loss = 0\n","    n_correct = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    \n","    model.train()\n","    for _, data in tqdm(enumerate(trainloader, 0)):\n","        ids = data['ids'].to(device, dtype=torch.long)\n","        mask = data['mask'].to(device, dtype=torch.long)\n","        targets = data['targets'].to(device, dtype=torch.long)\n","        \n","        outputs = model(ids, mask)\n","        loss = loss_function(outputs, targets)\n","        tr_loss += loss.item()\n","        big_val, big_idx = torch.max(outputs.data, dim=1)\n","        n_correct += calculate_acc(big_idx, targets)\n","        \n","        nb_tr_steps += 1\n","        nb_tr_examples += targets.size(0)\n","        \n","        if _ % 50 == 0:\n","            \n","            loss_step = tr_loss/nb_tr_steps\n","            acc_step = (n_correct*100)/nb_tr_examples\n","            print(f'Training Loss per 50 steps: {loss_step}, Training Accuracy: {acc_step}')\n","            writer.add_scalar('training_loss', loss_step, epoch*len(trainloader) +_)\n","            \n","            \n","        optimizer.zero_grad()\n","        loss.backward()\n","        \n","        optimizer.step()\n","        \n","    print(f'Total Accuracy Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_acc = (n_correct*100)/nb_tr_examples\n","    print(f'Training Loss Epoch: {epoch_loss}, Training Accuracy Epoch: {epoch_acc}')\n","    valid(model, valloader)\n","    return"],"metadata":{"id":"6PfZBRYnrHKI","executionInfo":{"status":"ok","timestamp":1643229178928,"user_tz":-330,"elapsed":429,"user":{"displayName":"Abhishek kumar Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03453965687970289686"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# Validation\n","\n","def valid(model, testloader):\n","    model.eval()\n","    n_correct =0; n_wrong =0; total=0; tr_loss =0; nb_tr_steps =0; nb_tr_examples=0\n","    y_pred, y_true = [],[]\n","    with torch.no_grad():\n","        for _, data in enumerate(testloader, 0):\n","            ids = data['ids'].to(device, dtype=torch.long)\n","            mask = data['mask'].to(device, dtype=torch.long)\n","            targets = data['targets'].to(device, dtype=torch.long)\n","            \n","            outputs = model(ids, mask)\n","            loss = loss_function(outputs, targets)\n","            tr_loss += loss.item()\n","            big_val, big_idx = torch.max(outputs.data, dim=1)\n","            n_correct += calculate_acc(big_idx, targets)\n","\n","            y_true.extend(targets.cpu().detach().numpy())\n","      \n","            y_pred.extend(torch.argmax(outputs, dim=1).cpu().detach().numpy())\n","            nb_tr_steps += 1\n","            nb_tr_examples += targets.size(0)\n","            \n","            if _ % 100 == 0:\n","                loss_step = tr_loss/nb_tr_steps\n","                acc_step = (n_correct*100)/nb_tr_examples\n","                #print(f'Validation Loss per 100 steps: {loss_step}, Validation Accuracy per: {acc_step}')   \n","        \n","    epoch_loss = tr_loss/nb_tr_steps\n","    epoch_acc = (n_correct*100)/nb_tr_examples\n","    print(f'Validation Loss Epoch: {epoch_loss}, Validation Accuracy Epoch: {epoch_acc}')\n","    \n","    return epoch_acc, y_true, y_pred"],"metadata":{"id":"ONoUGedzrOCa","executionInfo":{"status":"ok","timestamp":1643229187360,"user_tz":-330,"elapsed":457,"user":{"displayName":"Abhishek kumar Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03453965687970289686"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["for epoch in range(EPOCHS):\n","    train(epoch)"],"metadata":{"id":"5280kYfwrThg","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"0ec493f0-690d-4c7a-861e-1d570004be7e","executionInfo":{"status":"error","timestamp":1643229194867,"user_tz":-330,"elapsed":1152,"user":{"displayName":"Abhishek kumar Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03453965687970289686"}}},"execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":["0it [00:00, ?it/s]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-c6928e977afe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-36-30e6ee17e16f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-30-a499d9bc7079>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0moutput_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         )\n\u001b[1;32m   1108\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         \u001b[0mprediction_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mmasked_lm_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;31m# project back to size of vocabulary with bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.82 GiB (GPU 0; 14.76 GiB total capacity; 10.51 GiB already allocated; 745.75 MiB free; 12.57 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":["acc, y_true, y_pred = valid(model, testloader)"],"metadata":{"id":"XRlfHpozrXDW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643094006337,"user_tz":-330,"elapsed":134747,"user":{"displayName":"Abhishek kumar Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03453965687970289686"}},"outputId":"f681fea6-1bf7-4400-9fc4-2bbd505e694e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Validation Loss per 100 steps: 0.6403908133506775, Validation Accuracy per: 50.0\n","Validation Loss per 100 steps: 0.4539571699529591, Validation Accuracy per: 72.52475247524752\n","Validation Loss per 100 steps: 0.4451032114859244, Validation Accuracy per: 74.75124378109453\n","Validation Loss Epoch: 0.4503463284318684, Validation Accuracy Epoch: 74.16427889207259\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import accuracy_score\n","accuracy = confusion_matrix(y_true, y_pred)\n","print(accuracy)\n","from sklearn.metrics import classification_report\n","print(classification_report(y_true, y_pred))"],"metadata":{"id":"nuypq3rGub0r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1643094026908,"user_tz":-330,"elapsed":386,"user":{"displayName":"Abhishek kumar Singh","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03453965687970289686"}},"outputId":"daad5f80-3d3d-4417-9e19-08cefbff3df3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1368  516]\n"," [  25  185]]\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.73      0.83      1884\n","           1       0.26      0.88      0.41       210\n","\n","    accuracy                           0.74      2094\n","   macro avg       0.62      0.80      0.62      2094\n","weighted avg       0.91      0.74      0.79      2094\n","\n"]}]},{"cell_type":"code","source":["f =open('bert_roberta_small_test_1.txt', 'w')\n","for i in y_pred:\n","  print(i, file = f )\n","f.close()\n"],"metadata":{"id":"dLeClJNDv3Bz"},"execution_count":null,"outputs":[]}]}